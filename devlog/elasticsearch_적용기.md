# Elasticsearch 적용기

## 처음 구조

`title`과 `description`만 `Elasticsearch`에 저장하고 매칭되는 문서의 ID 값을 가져와서 DB로부터 조회하려고 했지만 이렇게 할 경우 페이징 처리가 안 됨.

그렇기에 Elasticsearch를 메인 DB로 사용하고 DB를 백업 용도로 포지션을 바꿨는데 Elasticsearch 역시 단점이 있음. RDBMS와 달리 인덱스를 한 번 생성하면 스키마를 변경할 수 없다는 것임. 즉 RDBMS의 경우 컬럼을 추가하거나 스키마를 변경할 수 있는데 Elasticsearch의 인덱스는 한 번 스키마를 만들면 중간에 변경하는 게 불가함. 그렇기에 데이터 구조가 바뀌면 인덱스를 한 번 삭제한 후에 다시 생성해야 하기 때문에 데이터 구조 변경에 따른 비용이 크다. 데이터 양이 기하급수적으로 많아지면 해당 데이터들을 다시 저장할 수도 없는 노릇이고... 이 문제는 아직도 해결 못한 난제로 남아 있다. 당장은 데이터 양이 많지 않은 테스트 단계지만 추후 데이터 규모가 커질 경우 확장성에 대한 고민도 해야 할 듯하다.

RDBMS에서 ID값을 기준으로 데이터를 가져오는 것은 왜 안 되느냐? 페이징 처리가 그 이유인데, 현재 검색의 경우 여러 오프셋 및 커서기반으로 페이징 처리가 되어 있는데, Elasticsearch를 온전히 검색 용도로만 사용할 경우, 1차적으로 Elasticsearch에서 keyword를 검색 후 매칭되는 ID값들을 받아와 2차로 DB에서 해당 ID값을 기반으로 데이터를 가져와야 한다. Elasticsearch를 시작으로 DB로 한 번의 요청에 총 두 번을 거쳐야 하기 때문에 이 역시 비효율성이 있을뿐더러 제일 중요한 페이징 처리가 제한된다는 단점이 있다. 예를 들어, 필터링되는 전체 데이터가 1000개라고 하면 Elasticsearch로붙 1000개의 ID값을 받아와서 SQL로 `... WHERE id in (1, 2, 3, 4 .... 1000)` <- 이런 식으로 써줘야 한다. RDBMS에서 `..WHERE id IN (1, 2, 3, ..., 1000)`와 같은 쿼리는 대량의 ID를 처리할 때 성능 저하가 발생할 수 있다. **IN** 절에 포함된 값이 많아질수록 쿼리 실행 시간이 길어지고, 데이터베이스의 인덱스 활용이 비효율적으로 작용할 수 있기 때문이다. 특히, 10,000개 이상의 ID를 처리하려면 쿼리가 복잡해지고, 데이터베이스의 부하가 크게 증가하며, 페이징 로직을 구현하기 어려워진다. 또한, 데이터가 10,000개가 넘어가면 또 다른 문ㅌ제가 생긴다. 여기서 10,000이란 숫자를 언급한 이유는 Elasticsearch에서 한 번에 가져올 수 있는 데이터가 10,000개이기 때문이다. 즉, 특정 키워드에 관련성이 있는 문서가 10,000개 이상이라면 전체 데이터 개수를 한 번에 가져올 수 없으므로 이전 페이지를 기억하는 데 제한이 생긴다. 이러한 이유 때문에 Elasticsearch에서 검색을 시행하고 RDBMS에서 세부적인 데이터를 가져오는 방식은 적절하지 않다고 판단했다.


<img width="500" alt="Image" src="https://github.com/user-attachments/assets/1b451e06-35ee-4d72-b227-f4d3b04916fd" />



## DB와 Elasticsearch 데이터 정합 문제

## Autocomplete
